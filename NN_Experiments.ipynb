{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLbXKh5eY6qh",
        "outputId": "aabc7b59-954e-4a0a-9985-f6b056d585eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/ML_trace_predictor/')"
      ],
      "metadata": {
        "id": "m3FW7CmIZIPN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import perceptron\n",
        "import features as f\n",
        "import numpy as np\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "metadata": {
        "id": "MSkfDZ3LZLFB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_length = 4\n",
        "num_of_classes = 16\n",
        "ifthenelse_filepath  = '/content/drive/My Drive/ML_trace_predictor/datafiles/ifthenelse/predictionAccuracy.csv'\n",
        "libquantum_filepath  = '/content/drive/My Drive/ML_trace_predictor/datafiles/short_libquantum/predictionAccuracy.csv'\n",
        "nested_filepath      = '/content/drive/My Drive/ML_trace_predictor/datafiles/nested/predictionAccuracy.csv'\n",
        "consecutive_filepath = '/content/drive/My Drive/ML_trace_predictor/datafiles/consecutive/predictionAccuracy.csv'\n",
        "\n",
        "\n",
        "#one-hot encoding\n",
        "consecutive_onehot_features, consecutive_onehot_labels = f.generateTraceFeatures(consecutive_filepath, history_length, num_of_classes)\n",
        "print (\"One-hot encoded features: \", consecutive_onehot_features.shape, \" Labels: \", consecutive_onehot_labels.shape)\n",
        "\n",
        "ifthenelse_features, ifthenelse_labels = f.generateTraceFeatures(ifthenelse_filepath, history_length, num_of_classes)\n",
        "print (\"One-hot encoded features: \", consecutive_onehot_features.shape, \" Labels: \", consecutive_onehot_labels.shape)\n",
        "\n",
        "nested_features, nested_onehot_labels = f.generateTraceFeatures(nested_filepath, history_length, num_of_classes)\n",
        "print (\"One-hot encoded features: \", consecutive_onehot_features.shape, \" Labels: \", consecutive_onehot_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4aBAUhTZMEk",
        "outputId": "6986531a-7e06-4ba7-9e6b-bdb9ed6518b8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One-hot encoded features:  (500496, 64)  Labels:  (500496,)\n",
            "One-hot encoded features:  (500496, 64)  Labels:  (500496,)\n",
            "One-hot encoded features:  (500496, 64)  Labels:  (500496,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indices = np.arange(consecutive_onehot_features.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "consecutive_onehot_features = consecutive_onehot_features[indices]\n",
        "consecutive_onehot_labels = consecutive_onehot_labels[indices].reshape(-1,1)\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "encoder.fit(consecutive_onehot_labels)\n",
        "consecutive_onehot_training_dataset = consecutive_onehot_features[:int(len(consecutive_onehot_features)*0.05)]\n",
        "consecutive_onehot_training_labels = consecutive_onehot_labels[:int(len(consecutive_onehot_labels)*0.05)]\n",
        "consecutive_onehot_val_dataset = consecutive_onehot_features[int(len(consecutive_onehot_features)*0.05):int(len(consecutive_onehot_features)*0.1)]\n",
        "consecutive_onehot_val_labels = consecutive_onehot_labels[int(len(consecutive_onehot_labels)*0.05):int(len(consecutive_onehot_labels)*0.1)]\n",
        "consecutive_onehot_test_dataset = consecutive_onehot_features[int(len(consecutive_onehot_features)*0.1):]\n",
        "consecutive_onehot_test_labels = consecutive_onehot_labels[int(len(consecutive_onehot_labels)*0.1):]\n",
        "consecutive_onehot_training_labels = encoder.transform(consecutive_onehot_training_labels)\n",
        "consecutive_onehot_val_labels = encoder.transform(consecutive_onehot_val_labels)\n",
        "consecutive_onehot_test_labels = encoder.transform(consecutive_onehot_test_labels)"
      ],
      "metadata": {
        "id": "3npEqVQWZ8PD"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indices = np.arange(ifthenelse_features.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "ifthenelse_features = ifthenelse_features[indices]\n",
        "ifthenelse_labels = ifthenelse_labels[indices].reshape(-1,1)\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "encoder.fit(ifthenelse_labels)\n",
        "ifthenelse_onehot_training_dataset = ifthenelse_features[:int(len(ifthenelse_features)*0.05)]\n",
        "ifthenelse_onehot_training_labels = ifthenelse_labels[:int(len(ifthenelse_labels)*0.05)]\n",
        "ifthenelse_onehot_val_dataset = ifthenelse_features[int(len(ifthenelse_features)*0.05):int(len(ifthenelse_features)*0.1)]\n",
        "ifthenelse_onehot_val_labels = ifthenelse_labels[int(len(ifthenelse_labels)*0.05):int(len(ifthenelse_labels)*0.1)]\n",
        "ifthenelse_onehot_test_dataset = ifthenelse_features[int(len(ifthenelse_features)*0.1):]\n",
        "ifthenelse_onehot_test_labels = ifthenelse_labels[int(len(ifthenelse_labels)*0.1):]\n",
        "ifthenelse_onehot_training_labels = encoder.transform(ifthenelse_onehot_training_labels)\n",
        "ifthenelse_onehot_val_labels = encoder.transform(ifthenelse_onehot_val_labels)\n",
        "ifthenelse_onehot_test_labels = encoder.transform(ifthenelse_onehot_test_labels)"
      ],
      "metadata": {
        "id": "39F1FjoEavMN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indices = np.arange(nested_features.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "nested_features = nested_features[indices]\n",
        "nested_onehot_labels = nested_onehot_labels[indices].reshape(-1,1)\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "encoder.fit(nested_onehot_labels)\n",
        "nested_onehot_training_dataset = nested_features[:int(len(nested_features)*0.05)]\n",
        "nested_onehot_training_labels = nested_onehot_labels[:int(len(nested_onehot_labels)*0.05)]\n",
        "nested_onehot_val_dataset = nested_features[int(len(nested_features)*0.05):int(len(nested_features)*0.1)]\n",
        "nested_onehot_val_labels = nested_onehot_labels[int(len(nested_onehot_labels)*0.05):int(len(nested_onehot_labels)*0.1)]\n",
        "nested_onehot_test_dataset = nested_features[int(len(nested_features)*0.1):]\n",
        "nested_onehot_test_labels = nested_onehot_labels[int(len(nested_onehot_labels)*0.1):]\n",
        "nested_onehot_training_labels = encoder.transform(nested_onehot_training_labels)\n",
        "nested_onehot_val_labels = encoder.transform(nested_onehot_val_labels)\n",
        "nested_onehot_test_labels = encoder.transform(nested_onehot_test_labels)"
      ],
      "metadata": {
        "id": "GepwztfNays7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(params,num_of_features,loss_fun,num_classes):\n",
        "    model=keras.Sequential()\n",
        "    model.add(keras.layers.Dense(units=num_of_features,activation='relu'))\n",
        "    for i in range (params['layers']):\n",
        "        model.add(keras.layers.Dense(units=params[\"N hidden\"],activation='relu'))\n",
        "        model.add(keras.layers.Dropout(params[\"dropout\"]))\n",
        "    model.add(keras.layers.Dense(num_classes,activation='softmax'))\n",
        "    Adam=keras.optimizers.Adam(learning_rate=params[\"lr\"],decay=params[\"lrd\"])\n",
        "    model.compile(optimizer= Adam,loss=loss_fun,metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "2__xFqttcBdj"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "    \n",
        "def random_search(params,num_iterations,x_train,y_train,x_test,y_test,num_of_features,num_classes,dataset):\n",
        "    models={}\n",
        "    mc=keras.callbacks.ModelCheckpoint(monitor='val_accuracy', mode='max', save_best_only=True,verbose=1,filepath='/content/drive/My Drive/ML_trace_predictor/' + dataset + '.h5')\n",
        "    for i in range (num_iterations):\n",
        "        print(\"iteration: \"+str(i))\n",
        "        passing_params={}\n",
        "        passing_params[\"layers\"] = random.choice(params[\"layers\"])\n",
        "        passing_params[\"lr\"]=random.choice(params[\"lr\"])\n",
        "        passing_params[\"N hidden\"]= random.choice(params[\"N hidden\"])\n",
        "        passing_params[\"Mini-batch size\"]= random.choice(params[\"Mini-batch size\"])\n",
        "        passing_params [\"lrd\"]= random.choice(params[\"lrd\"])\n",
        "        passing_params [\"dropout\"]=random.choice(params[\"dropout\"])\n",
        "        print(passing_params)\n",
        "        model=create_model(passing_params,num_of_features,'categorical_crossentropy',num_classes)\n",
        "        es=keras.callbacks.EarlyStopping(monitor='val_accuracy', mode='min', verbose=1, patience=4,min_delta=0.05)\n",
        "        history=model.fit(x_train,y_train,validation_data=(x_test,y_test),epochs=100,batch_size=passing_params[\"Mini-batch size\"],callbacks=[es,mc], verbose=1)\n",
        "        val_accuracy=history.history['val_accuracy'][-1]\n",
        "        models.update({str(passing_params):(val_accuracy)})\n",
        "    return models\n",
        "\n",
        "params={\"lr\":[0.0001,0.001,0.01,0.1],\n",
        "       \"dropout\":[0,0.3,0.4],\n",
        "       \"N hidden\":[4,5,8,10,20,25],\n",
        "       \"Mini-batch size\":[8,16,32,64],\n",
        "        \"lrd\":[0.0001,0.001,0.01,0.1],\n",
        "        \"layers\":[1,2,3,4]\n",
        "}"
      ],
      "metadata": {
        "id": "nxzrBogRZlHo"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "consecutive_models = random_search(params,10,consecutive_onehot_training_dataset,consecutive_onehot_training_labels,consecutive_onehot_val_dataset,consecutive_onehot_val_labels,consecutive_onehot_training_dataset.shape[1],consecutive_onehot_training_labels.shape[1],\"consecutive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daODsLfccGvg",
        "outputId": "e3bae923-6227-4c3c-c940-7dcbf9ed1973"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration: 0\n",
            "{'layers': 3, 'lr': 0.0001, 'N hidden': 8, 'Mini-batch size': 8, 'lrd': 0.1, 'dropout': 0.3}\n",
            "Epoch 1/100\n",
            "3124/3128 [============================>.] - ETA: 0s - loss: 1.3601 - accuracy: 0.4238\n",
            "Epoch 1: val_accuracy improved from -inf to 0.66422, saving model to /content/drive/My Drive/ML_trace_predictor/consecutive.h5\n",
            "3128/3128 [==============================] - 12s 4ms/step - loss: 1.3600 - accuracy: 0.4238 - val_loss: 1.3529 - val_accuracy: 0.6642\n",
            "Epoch 2/100\n",
            "3122/3128 [============================>.] - ETA: 0s - loss: 1.3574 - accuracy: 0.4401\n",
            "Epoch 2: val_accuracy did not improve from 0.66422\n",
            "3128/3128 [==============================] - 12s 4ms/step - loss: 1.3574 - accuracy: 0.4401 - val_loss: 1.3512 - val_accuracy: 0.6642\n",
            "Epoch 3/100\n",
            "3119/3128 [============================>.] - ETA: 0s - loss: 1.3556 - accuracy: 0.4431\n",
            "Epoch 3: val_accuracy did not improve from 0.66422\n",
            "3128/3128 [==============================] - 11s 4ms/step - loss: 1.3556 - accuracy: 0.4428 - val_loss: 1.3502 - val_accuracy: 0.6642\n",
            "Epoch 4/100\n",
            "3117/3128 [============================>.] - ETA: 0s - loss: 1.3557 - accuracy: 0.4444\n",
            "Epoch 4: val_accuracy did not improve from 0.66422\n",
            "3128/3128 [==============================] - 13s 4ms/step - loss: 1.3557 - accuracy: 0.4443 - val_loss: 1.3495 - val_accuracy: 0.6642\n",
            "Epoch 5/100\n",
            "3118/3128 [============================>.] - ETA: 0s - loss: 1.3543 - accuracy: 0.4482\n",
            "Epoch 5: val_accuracy did not improve from 0.66422\n",
            "3128/3128 [==============================] - 11s 4ms/step - loss: 1.3542 - accuracy: 0.4484 - val_loss: 1.3490 - val_accuracy: 0.6642\n",
            "Epoch 5: early stopping\n",
            "iteration: 1\n",
            "{'layers': 4, 'lr': 0.1, 'N hidden': 25, 'Mini-batch size': 32, 'lrd': 0.1, 'dropout': 0.4}\n",
            "Epoch 1/100\n",
            "773/782 [============================>.] - ETA: 0s - loss: 0.4408 - accuracy: 0.8021\n",
            "Epoch 1: val_accuracy improved from 0.66422 to 0.99908, saving model to /content/drive/My Drive/ML_trace_predictor/consecutive.h5\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.4395 - accuracy: 0.8029 - val_loss: 0.1358 - val_accuracy: 0.9991\n",
            "Epoch 2/100\n",
            "774/782 [============================>.] - ETA: 0s - loss: 0.3194 - accuracy: 0.8733\n",
            "Epoch 2: val_accuracy did not improve from 0.99908\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.3191 - accuracy: 0.8733 - val_loss: 0.1057 - val_accuracy: 0.9991\n",
            "Epoch 3/100\n",
            "770/782 [============================>.] - ETA: 0s - loss: 0.3096 - accuracy: 0.8794\n",
            "Epoch 3: val_accuracy did not improve from 0.99908\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.3101 - accuracy: 0.8795 - val_loss: 0.0997 - val_accuracy: 0.9991\n",
            "Epoch 4/100\n",
            "775/782 [============================>.] - ETA: 0s - loss: 0.3014 - accuracy: 0.8830\n",
            "Epoch 4: val_accuracy did not improve from 0.99908\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.3012 - accuracy: 0.8829 - val_loss: 0.0901 - val_accuracy: 0.9991\n",
            "Epoch 5/100\n",
            "769/782 [============================>.] - ETA: 0s - loss: 0.2980 - accuracy: 0.8821\n",
            "Epoch 5: val_accuracy did not improve from 0.99908\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.2987 - accuracy: 0.8824 - val_loss: 0.0871 - val_accuracy: 0.9991\n",
            "Epoch 5: early stopping\n",
            "iteration: 2\n",
            "{'layers': 2, 'lr': 0.1, 'N hidden': 8, 'Mini-batch size': 64, 'lrd': 0.0001, 'dropout': 0.4}\n",
            "Epoch 1/100\n",
            "369/391 [===========================>..] - ETA: 0s - loss: 0.8574 - accuracy: 0.6109\n",
            "Epoch 1: val_accuracy did not improve from 0.99908\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.8617 - accuracy: 0.6069 - val_loss: 0.7510 - val_accuracy: 0.5941\n",
            "Epoch 2/100\n",
            "383/391 [============================>.] - ETA: 0s - loss: 0.9264 - accuracy: 0.5527\n",
            "Epoch 2: val_accuracy did not improve from 0.99908\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.9258 - accuracy: 0.5524 - val_loss: 0.7432 - val_accuracy: 0.5941\n",
            "Epoch 3/100\n",
            "380/391 [============================>.] - ETA: 0s - loss: 0.9267 - accuracy: 0.5486\n",
            "Epoch 3: val_accuracy did not improve from 0.99908\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.9257 - accuracy: 0.5490 - val_loss: 0.7412 - val_accuracy: 0.5941\n",
            "Epoch 4/100\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.9291 - accuracy: 0.5492\n",
            "Epoch 4: val_accuracy did not improve from 0.99908\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.9288 - accuracy: 0.5494 - val_loss: 0.7771 - val_accuracy: 0.5941\n",
            "Epoch 5/100\n",
            "374/391 [===========================>..] - ETA: 0s - loss: 0.9276 - accuracy: 0.5549\n",
            "Epoch 5: val_accuracy did not improve from 0.99908\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.9282 - accuracy: 0.5549 - val_loss: 0.7449 - val_accuracy: 0.5941\n",
            "Epoch 5: early stopping\n",
            "iteration: 3\n",
            "{'layers': 1, 'lr': 0.0001, 'N hidden': 8, 'Mini-batch size': 32, 'lrd': 0.001, 'dropout': 0}\n",
            "Epoch 1/100\n",
            "780/782 [============================>.] - ETA: 0s - loss: 1.0559 - accuracy: 0.7033\n",
            "Epoch 1: val_accuracy did not improve from 0.99908\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.0553 - accuracy: 0.7036 - val_loss: 0.8065 - val_accuracy: 0.7988\n",
            "Epoch 2/100\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.6455 - accuracy: 0.8009\n",
            "Epoch 2: val_accuracy did not improve from 0.99908\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.6455 - accuracy: 0.8009 - val_loss: 0.5202 - val_accuracy: 0.7988\n",
            "Epoch 3/100\n",
            "770/782 [============================>.] - ETA: 0s - loss: 0.4392 - accuracy: 0.8266\n",
            "Epoch 3: val_accuracy did not improve from 0.99908\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.4385 - accuracy: 0.8283 - val_loss: 0.3707 - val_accuracy: 0.9326\n",
            "Epoch 4/100\n",
            "777/782 [============================>.] - ETA: 0s - loss: 0.3217 - accuracy: 0.9482\n",
            "Epoch 4: val_accuracy did not improve from 0.99908\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 0.3213 - accuracy: 0.9485 - val_loss: 0.2787 - val_accuracy: 0.9991\n",
            "Epoch 5/100\n",
            "770/782 [============================>.] - ETA: 0s - loss: 0.2470 - accuracy: 0.9987\n",
            "Epoch 5: val_accuracy did not improve from 0.99908\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.2467 - accuracy: 0.9987 - val_loss: 0.2181 - val_accuracy: 0.9991\n",
            "Epoch 5: early stopping\n",
            "iteration: 4\n",
            "{'layers': 2, 'lr': 0.1, 'N hidden': 10, 'Mini-batch size': 8, 'lrd': 0.001, 'dropout': 0.4}\n",
            "Epoch 1/100\n",
            "3118/3128 [============================>.] - ETA: 0s - loss: 1.0698 - accuracy: 0.5862\n",
            "Epoch 1: val_accuracy did not improve from 0.99908\n",
            "3128/3128 [==============================] - 13s 4ms/step - loss: 1.0697 - accuracy: 0.5862 - val_loss: 1.0484 - val_accuracy: 0.5947\n",
            "Epoch 2/100\n",
            "3110/3128 [============================>.] - ETA: 0s - loss: 1.0686 - accuracy: 0.5831\n",
            "Epoch 2: val_accuracy did not improve from 0.99908\n",
            "3128/3128 [==============================] - 11s 4ms/step - loss: 1.0685 - accuracy: 0.5833 - val_loss: 1.0492 - val_accuracy: 0.5947\n",
            "Epoch 3/100\n",
            "3107/3128 [============================>.] - ETA: 0s - loss: 1.0676 - accuracy: 0.5828\n",
            "Epoch 3: val_accuracy did not improve from 0.99908\n",
            "3128/3128 [==============================] - 11s 4ms/step - loss: 1.0681 - accuracy: 0.5828 - val_loss: 1.0494 - val_accuracy: 0.5947\n",
            "Epoch 4/100\n",
            "3108/3128 [============================>.] - ETA: 0s - loss: 1.0672 - accuracy: 0.5833\n",
            "Epoch 4: val_accuracy did not improve from 0.99908\n",
            "3128/3128 [==============================] - 12s 4ms/step - loss: 1.0668 - accuracy: 0.5835 - val_loss: 1.0475 - val_accuracy: 0.5947\n",
            "Epoch 5/100\n",
            "3117/3128 [============================>.] - ETA: 0s - loss: 1.0640 - accuracy: 0.5853\n",
            "Epoch 5: val_accuracy did not improve from 0.99908\n",
            "3128/3128 [==============================] - 13s 4ms/step - loss: 1.0642 - accuracy: 0.5851 - val_loss: 1.0479 - val_accuracy: 0.5947\n",
            "Epoch 5: early stopping\n",
            "iteration: 5\n",
            "{'layers': 1, 'lr': 0.0001, 'N hidden': 4, 'Mini-batch size': 64, 'lrd': 0.0001, 'dropout': 0.3}\n",
            "Epoch 1/100\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.3269 - accuracy: 0.3671\n",
            "Epoch 1: val_accuracy did not improve from 0.99908\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 1.3269 - accuracy: 0.3671 - val_loss: 1.1999 - val_accuracy: 0.5955\n",
            "Epoch 2/100\n",
            "374/391 [===========================>..] - ETA: 0s - loss: 1.0884 - accuracy: 0.4989\n",
            "Epoch 2: val_accuracy did not improve from 0.99908\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 1.0827 - accuracy: 0.4999 - val_loss: 0.9085 - val_accuracy: 0.5266\n",
            "Epoch 3/100\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.8649 - accuracy: 0.5512\n",
            "Epoch 3: val_accuracy did not improve from 0.99908\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.8642 - accuracy: 0.5520 - val_loss: 0.6940 - val_accuracy: 0.5941\n",
            "Epoch 4/100\n",
            "372/391 [===========================>..] - ETA: 0s - loss: 0.7140 - accuracy: 0.7252\n",
            "Epoch 4: val_accuracy did not improve from 0.99908\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.7104 - accuracy: 0.7287 - val_loss: 0.5478 - val_accuracy: 0.9319\n",
            "Epoch 5/100\n",
            "373/391 [===========================>..] - ETA: 0s - loss: 0.6090 - accuracy: 0.8184\n",
            "Epoch 5: val_accuracy did not improve from 0.99908\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.6070 - accuracy: 0.8201 - val_loss: 0.4420 - val_accuracy: 0.9326\n",
            "Epoch 6/100\n",
            "385/391 [============================>.] - ETA: 0s - loss: 0.5373 - accuracy: 0.8451\n",
            "Epoch 6: val_accuracy did not improve from 0.99908\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.5370 - accuracy: 0.8449 - val_loss: 0.3634 - val_accuracy: 0.9326\n",
            "Epoch 6: early stopping\n",
            "iteration: 6\n",
            "{'layers': 4, 'lr': 0.1, 'N hidden': 20, 'Mini-batch size': 16, 'lrd': 0.0001, 'dropout': 0}\n",
            "Epoch 1/100\n",
            "1557/1564 [============================>.] - ETA: 0s - loss: 0.2758 - accuracy: 0.9072\n",
            "Epoch 1: val_accuracy did not improve from 0.99908\n",
            "1564/1564 [==============================] - 7s 4ms/step - loss: 0.2754 - accuracy: 0.9072 - val_loss: 0.1892 - val_accuracy: 0.9319\n",
            "Epoch 2/100\n",
            "1563/1564 [============================>.] - ETA: 0s - loss: 0.6677 - accuracy: 0.7366\n",
            "Epoch 2: val_accuracy did not improve from 0.99908\n",
            "1564/1564 [==============================] - 6s 4ms/step - loss: 0.6679 - accuracy: 0.7365 - val_loss: 1.1462 - val_accuracy: 0.5266\n",
            "Epoch 3/100\n",
            "1553/1564 [============================>.] - ETA: 0s - loss: 1.1418 - accuracy: 0.5341\n",
            "Epoch 3: val_accuracy did not improve from 0.99908\n",
            "1564/1564 [==============================] - 6s 4ms/step - loss: 1.1413 - accuracy: 0.5344 - val_loss: 1.1559 - val_accuracy: 0.5266\n",
            "Epoch 4/100\n",
            "1545/1564 [============================>.] - ETA: 0s - loss: 1.1399 - accuracy: 0.5344\n",
            "Epoch 4: val_accuracy did not improve from 0.99908\n",
            "1564/1564 [==============================] - 6s 4ms/step - loss: 1.1399 - accuracy: 0.5344 - val_loss: 1.1445 - val_accuracy: 0.5266\n",
            "Epoch 5/100\n",
            "1555/1564 [============================>.] - ETA: 0s - loss: 1.1402 - accuracy: 0.5344\n",
            "Epoch 5: val_accuracy did not improve from 0.99908\n",
            "1564/1564 [==============================] - 6s 4ms/step - loss: 1.1400 - accuracy: 0.5344 - val_loss: 1.1468 - val_accuracy: 0.5266\n",
            "Epoch 6/100\n",
            "1557/1564 [============================>.] - ETA: 0s - loss: 1.1398 - accuracy: 0.5342\n",
            "Epoch 6: val_accuracy did not improve from 0.99908\n",
            "1564/1564 [==============================] - 9s 6ms/step - loss: 1.1394 - accuracy: 0.5344 - val_loss: 1.1454 - val_accuracy: 0.5266\n",
            "Epoch 6: early stopping\n",
            "iteration: 7\n",
            "{'layers': 4, 'lr': 0.01, 'N hidden': 8, 'Mini-batch size': 32, 'lrd': 0.1, 'dropout': 0.4}\n",
            "Epoch 1/100\n",
            "782/782 [==============================] - ETA: 0s - loss: 1.0008 - accuracy: 0.6636\n",
            "Epoch 1: val_accuracy did not improve from 0.99908\n",
            "782/782 [==============================] - 4s 4ms/step - loss: 1.0008 - accuracy: 0.6636 - val_loss: 0.6509 - val_accuracy: 0.7981\n",
            "Epoch 2/100\n",
            "766/782 [============================>.] - ETA: 0s - loss: 0.8974 - accuracy: 0.6837\n",
            "Epoch 2: val_accuracy did not improve from 0.99908\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.8969 - accuracy: 0.6836 - val_loss: 0.5920 - val_accuracy: 0.7981\n",
            "Epoch 3/100\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.8620 - accuracy: 0.6911\n",
            "Epoch 3: val_accuracy did not improve from 0.99908\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.8620 - accuracy: 0.6911 - val_loss: 0.5576 - val_accuracy: 0.7988\n",
            "Epoch 4/100\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.8495 - accuracy: 0.6913\n",
            "Epoch 4: val_accuracy did not improve from 0.99908\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.8495 - accuracy: 0.6913 - val_loss: 0.5392 - val_accuracy: 0.7988\n",
            "Epoch 5/100\n",
            "769/782 [============================>.] - ETA: 0s - loss: 0.8404 - accuracy: 0.6901\n",
            "Epoch 5: val_accuracy did not improve from 0.99908\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.8397 - accuracy: 0.6906 - val_loss: 0.5243 - val_accuracy: 0.7988\n",
            "Epoch 5: early stopping\n",
            "iteration: 8\n",
            "{'layers': 1, 'lr': 0.001, 'N hidden': 8, 'Mini-batch size': 32, 'lrd': 0.0001, 'dropout': 0.4}\n",
            "Epoch 1/100\n",
            "775/782 [============================>.] - ETA: 0s - loss: 0.6284 - accuracy: 0.8051\n",
            "Epoch 1: val_accuracy did not improve from 0.99908\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.6261 - accuracy: 0.8059 - val_loss: 0.3499 - val_accuracy: 0.9326\n",
            "Epoch 2/100\n",
            "779/782 [============================>.] - ETA: 0s - loss: 0.3433 - accuracy: 0.8995\n",
            "Epoch 2: val_accuracy did not improve from 0.99908\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 0.3427 - accuracy: 0.8996 - val_loss: 0.2470 - val_accuracy: 0.9326\n",
            "Epoch 3/100\n",
            "777/782 [============================>.] - ETA: 0s - loss: 0.2585 - accuracy: 0.9164\n",
            "Epoch 3: val_accuracy did not improve from 0.99908\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.2587 - accuracy: 0.9165 - val_loss: 0.1437 - val_accuracy: 0.9991\n",
            "Epoch 4/100\n",
            "765/782 [============================>.] - ETA: 0s - loss: 0.2153 - accuracy: 0.9447\n",
            "Epoch 4: val_accuracy did not improve from 0.99908\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.2146 - accuracy: 0.9448 - val_loss: 0.1095 - val_accuracy: 0.9991\n",
            "Epoch 5/100\n",
            "766/782 [============================>.] - ETA: 0s - loss: 0.2035 - accuracy: 0.9398\n",
            "Epoch 5: val_accuracy did not improve from 0.99908\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.2034 - accuracy: 0.9397 - val_loss: 0.0972 - val_accuracy: 0.9991\n",
            "Epoch 5: early stopping\n",
            "iteration: 9\n",
            "{'layers': 3, 'lr': 0.001, 'N hidden': 20, 'Mini-batch size': 32, 'lrd': 0.0001, 'dropout': 0.3}\n",
            "Epoch 1/100\n",
            "770/782 [============================>.] - ETA: 0s - loss: 0.3089 - accuracy: 0.8878\n",
            "Epoch 1: val_accuracy did not improve from 0.99908\n",
            "782/782 [==============================] - 4s 4ms/step - loss: 0.3053 - accuracy: 0.8893 - val_loss: 0.0250 - val_accuracy: 0.9991\n",
            "Epoch 2/100\n",
            "766/782 [============================>.] - ETA: 0s - loss: 0.0543 - accuracy: 0.9873\n",
            "Epoch 2: val_accuracy did not improve from 0.99908\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.0541 - accuracy: 0.9873 - val_loss: 0.0109 - val_accuracy: 0.9991\n",
            "Epoch 3/100\n",
            "761/782 [============================>.] - ETA: 0s - loss: 0.0400 - accuracy: 0.9922\n",
            "Epoch 3: val_accuracy did not improve from 0.99908\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.0404 - accuracy: 0.9920 - val_loss: 0.0069 - val_accuracy: 0.9991\n",
            "Epoch 4/100\n",
            "778/782 [============================>.] - ETA: 0s - loss: 0.0355 - accuracy: 0.9918\n",
            "Epoch 4: val_accuracy did not improve from 0.99908\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.0354 - accuracy: 0.9918 - val_loss: 0.0096 - val_accuracy: 0.9991\n",
            "Epoch 5/100\n",
            "777/782 [============================>.] - ETA: 0s - loss: 0.0314 - accuracy: 0.9939\n",
            "Epoch 5: val_accuracy did not improve from 0.99908\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.0312 - accuracy: 0.9940 - val_loss: 0.0077 - val_accuracy: 0.9991\n",
            "Epoch 5: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_consecutive = [key for key, value in consecutive_models.items() if value == max(consecutive_models.values())]\n",
        "print(best_model_consecutive)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqvUlDYnevz9",
        "outputId": "9128ac98-3045-4fac-ddf8-1e2172d4820e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"{'layers': 4, 'lr': 0.1, 'N hidden': 25, 'Mini-batch size': 32, 'lrd': 0.1, 'dropout': 0.4}\", \"{'layers': 1, 'lr': 0.0001, 'N hidden': 8, 'Mini-batch size': 32, 'lrd': 0.001, 'dropout': 0}\", \"{'layers': 1, 'lr': 0.001, 'N hidden': 8, 'Mini-batch size': 32, 'lrd': 0.0001, 'dropout': 0.4}\", \"{'layers': 3, 'lr': 0.001, 'N hidden': 20, 'Mini-batch size': 32, 'lrd': 0.0001, 'dropout': 0.3}\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_params_consecutive = {'layers': 4, 'lr': 0.1, 'N hidden': 25, 'Mini-batch size': 32, 'lrd': 0.1, 'dropout': 0.4}"
      ],
      "metadata": {
        "id": "Iym_gftme36U"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reconstructed_best_model_consecutive = keras.models.load_model(\"/content/drive/My Drive/ML_trace_predictor/consecutive.h5\")"
      ],
      "metadata": {
        "id": "dQSY2v6ce9xc"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = reconstructed_best_model_consecutive.evaluate(consecutive_onehot_test_dataset, consecutive_onehot_test_labels, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_Idg8kzfpXI",
        "outputId": "083d3459-b2a2-439f-8d6a-9077b8a98267"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.1360294222831726\n",
            "Test accuracy: 0.9990143179893494\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ifthenelse_models = random_search(params,10,ifthenelse_onehot_training_dataset,ifthenelse_onehot_training_labels,ifthenelse_onehot_val_dataset,ifthenelse_onehot_val_labels,ifthenelse_onehot_training_dataset.shape[1],ifthenelse_onehot_training_labels.shape[1],\"ifthenelse\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQUeiwj-gUvs",
        "outputId": "f5cd45e8-0c6a-4b51-82a3-6b8d9545dd0a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration: 0\n",
            "{'layers': 4, 'lr': 0.001, 'N hidden': 25, 'Mini-batch size': 16, 'lrd': 0.0001, 'dropout': 0.3}\n",
            "Epoch 1/100\n",
            "1553/1564 [============================>.] - ETA: 0s - loss: 0.2907 - accuracy: 0.8570\n",
            "Epoch 1: val_accuracy improved from -inf to 0.85882, saving model to /content/drive/My Drive/ML_trace_predictor/ifthenelse.h5\n",
            "1564/1564 [==============================] - 8s 5ms/step - loss: 0.2907 - accuracy: 0.8571 - val_loss: 0.2709 - val_accuracy: 0.8588\n",
            "Epoch 2/100\n",
            "1564/1564 [==============================] - ETA: 0s - loss: 0.2706 - accuracy: 0.8600\n",
            "Epoch 2: val_accuracy did not improve from 0.85882\n",
            "1564/1564 [==============================] - 7s 4ms/step - loss: 0.2706 - accuracy: 0.8600 - val_loss: 0.2709 - val_accuracy: 0.8588\n",
            "Epoch 3/100\n",
            "1556/1564 [============================>.] - ETA: 0s - loss: 0.2704 - accuracy: 0.8601\n",
            "Epoch 3: val_accuracy did not improve from 0.85882\n",
            "1564/1564 [==============================] - 6s 4ms/step - loss: 0.2706 - accuracy: 0.8600 - val_loss: 0.2711 - val_accuracy: 0.8588\n",
            "Epoch 4/100\n",
            "1552/1564 [============================>.] - ETA: 0s - loss: 0.2706 - accuracy: 0.8601\n",
            "Epoch 4: val_accuracy did not improve from 0.85882\n",
            "1564/1564 [==============================] - 7s 4ms/step - loss: 0.2706 - accuracy: 0.8600 - val_loss: 0.2709 - val_accuracy: 0.8588\n",
            "Epoch 5/100\n",
            "1559/1564 [============================>.] - ETA: 0s - loss: 0.2701 - accuracy: 0.8600\n",
            "Epoch 5: val_accuracy did not improve from 0.85882\n",
            "1564/1564 [==============================] - 9s 6ms/step - loss: 0.2701 - accuracy: 0.8600 - val_loss: 0.2710 - val_accuracy: 0.8588\n",
            "Epoch 5: early stopping\n",
            "iteration: 1\n",
            "{'layers': 1, 'lr': 0.01, 'N hidden': 5, 'Mini-batch size': 8, 'lrd': 0.001, 'dropout': 0.4}\n",
            "Epoch 1/100\n",
            "3105/3128 [============================>.] - ETA: 0s - loss: 0.4088 - accuracy: 0.8594\n",
            "Epoch 1: val_accuracy did not improve from 0.85882\n",
            "3128/3128 [==============================] - 13s 4ms/step - loss: 0.4086 - accuracy: 0.8595 - val_loss: 0.4073 - val_accuracy: 0.8588\n",
            "Epoch 2/100\n",
            "3112/3128 [============================>.] - ETA: 0s - loss: 0.4053 - accuracy: 0.8599\n",
            "Epoch 2: val_accuracy did not improve from 0.85882\n",
            "3128/3128 [==============================] - 11s 4ms/step - loss: 0.4051 - accuracy: 0.8600 - val_loss: 0.4073 - val_accuracy: 0.8588\n",
            "Epoch 3/100\n",
            "3127/3128 [============================>.] - ETA: 0s - loss: 0.4051 - accuracy: 0.8600\n",
            "Epoch 3: val_accuracy did not improve from 0.85882\n",
            "3128/3128 [==============================] - 10s 3ms/step - loss: 0.4051 - accuracy: 0.8600 - val_loss: 0.4071 - val_accuracy: 0.8588\n",
            "Epoch 4/100\n",
            "3104/3128 [============================>.] - ETA: 0s - loss: 0.4051 - accuracy: 0.8600\n",
            "Epoch 4: val_accuracy did not improve from 0.85882\n",
            "3128/3128 [==============================] - 10s 3ms/step - loss: 0.4051 - accuracy: 0.8600 - val_loss: 0.4071 - val_accuracy: 0.8588\n",
            "Epoch 5/100\n",
            "3115/3128 [============================>.] - ETA: 0s - loss: 0.4052 - accuracy: 0.8599\n",
            "Epoch 5: val_accuracy did not improve from 0.85882\n",
            "3128/3128 [==============================] - 12s 4ms/step - loss: 0.4051 - accuracy: 0.8600 - val_loss: 0.4071 - val_accuracy: 0.8588\n",
            "Epoch 5: early stopping\n",
            "iteration: 2\n",
            "{'layers': 4, 'lr': 0.1, 'N hidden': 25, 'Mini-batch size': 64, 'lrd': 0.001, 'dropout': 0.4}\n",
            "Epoch 1/100\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.4963 - accuracy: 0.8573\n",
            "Epoch 1: val_accuracy did not improve from 0.85882\n",
            "391/391 [==============================] - 5s 9ms/step - loss: 0.4958 - accuracy: 0.8575 - val_loss: 0.4071 - val_accuracy: 0.8588\n",
            "Epoch 2/100\n",
            "385/391 [============================>.] - ETA: 0s - loss: 0.4064 - accuracy: 0.8598\n",
            "Epoch 2: val_accuracy did not improve from 0.85882\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.4060 - accuracy: 0.8600 - val_loss: 0.4086 - val_accuracy: 0.8588\n",
            "Epoch 3/100\n",
            "383/391 [============================>.] - ETA: 0s - loss: 0.4070 - accuracy: 0.8598\n",
            "Epoch 3: val_accuracy did not improve from 0.85882\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.4066 - accuracy: 0.8600 - val_loss: 0.4096 - val_accuracy: 0.8588\n",
            "Epoch 4/100\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.4062 - accuracy: 0.8600\n",
            "Epoch 4: val_accuracy did not improve from 0.85882\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.4062 - accuracy: 0.8600 - val_loss: 0.4078 - val_accuracy: 0.8588\n",
            "Epoch 5/100\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.4059 - accuracy: 0.8600\n",
            "Epoch 5: val_accuracy did not improve from 0.85882\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.4059 - accuracy: 0.8600 - val_loss: 0.4100 - val_accuracy: 0.8588\n",
            "Epoch 5: early stopping\n",
            "iteration: 3\n",
            "{'layers': 3, 'lr': 0.1, 'N hidden': 10, 'Mini-batch size': 32, 'lrd': 0.1, 'dropout': 0}\n",
            "Epoch 1/100\n",
            "766/782 [============================>.] - ETA: 0s - loss: 0.3037 - accuracy: 0.8587\n",
            "Epoch 1: val_accuracy did not improve from 0.85882\n",
            "782/782 [==============================] - 7s 6ms/step - loss: 0.3028 - accuracy: 0.8591 - val_loss: 0.2710 - val_accuracy: 0.8588\n",
            "Epoch 2/100\n",
            "779/782 [============================>.] - ETA: 0s - loss: 0.2700 - accuracy: 0.8600\n",
            "Epoch 2: val_accuracy did not improve from 0.85882\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.2699 - accuracy: 0.8600 - val_loss: 0.2709 - val_accuracy: 0.8588\n",
            "Epoch 3/100\n",
            "775/782 [============================>.] - ETA: 0s - loss: 0.2703 - accuracy: 0.8598\n",
            "Epoch 3: val_accuracy did not improve from 0.85882\n",
            "782/782 [==============================] - 4s 4ms/step - loss: 0.2699 - accuracy: 0.8600 - val_loss: 0.2709 - val_accuracy: 0.8588\n",
            "Epoch 4/100\n",
            "763/782 [============================>.] - ETA: 0s - loss: 0.2701 - accuracy: 0.8597\n",
            "Epoch 4: val_accuracy did not improve from 0.85882\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.2699 - accuracy: 0.8600 - val_loss: 0.2709 - val_accuracy: 0.8588\n",
            "Epoch 5/100\n",
            "777/782 [============================>.] - ETA: 0s - loss: 0.2700 - accuracy: 0.8599\n",
            "Epoch 5: val_accuracy did not improve from 0.85882\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.2699 - accuracy: 0.8600 - val_loss: 0.2709 - val_accuracy: 0.8588\n",
            "Epoch 5: early stopping\n",
            "iteration: 4\n",
            "{'layers': 1, 'lr': 0.001, 'N hidden': 25, 'Mini-batch size': 64, 'lrd': 0.01, 'dropout': 0.4}\n",
            "Epoch 1/100\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.3564 - accuracy: 0.8550\n",
            "Epoch 1: val_accuracy did not improve from 0.85882\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.3558 - accuracy: 0.8549 - val_loss: 0.2902 - val_accuracy: 0.8588\n",
            "Epoch 2/100\n",
            "375/391 [===========================>..] - ETA: 0s - loss: 0.2947 - accuracy: 0.8575\n",
            "Epoch 2: val_accuracy did not improve from 0.85882\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.2941 - accuracy: 0.8575 - val_loss: 0.2780 - val_accuracy: 0.8588\n",
            "Epoch 3/100\n",
            "383/391 [============================>.] - ETA: 0s - loss: 0.2845 - accuracy: 0.8587\n",
            "Epoch 3: val_accuracy did not improve from 0.85882\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.2848 - accuracy: 0.8585 - val_loss: 0.2747 - val_accuracy: 0.8588\n",
            "Epoch 4/100\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2813 - accuracy: 0.8589\n",
            "Epoch 4: val_accuracy did not improve from 0.85882\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.2813 - accuracy: 0.8589 - val_loss: 0.2732 - val_accuracy: 0.8588\n",
            "Epoch 5/100\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.2786 - accuracy: 0.8592\n",
            "Epoch 5: val_accuracy did not improve from 0.85882\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.2785 - accuracy: 0.8594 - val_loss: 0.2728 - val_accuracy: 0.8588\n",
            "Epoch 5: early stopping\n",
            "iteration: 5\n",
            "{'layers': 2, 'lr': 0.01, 'N hidden': 25, 'Mini-batch size': 16, 'lrd': 0.0001, 'dropout': 0}\n",
            "Epoch 1/100\n",
            "1557/1564 [============================>.] - ETA: 0s - loss: 0.2732 - accuracy: 0.8591\n",
            "Epoch 1: val_accuracy did not improve from 0.85882\n",
            "1564/1564 [==============================] - 7s 4ms/step - loss: 0.2730 - accuracy: 0.8592 - val_loss: 0.2709 - val_accuracy: 0.8588\n",
            "Epoch 2/100\n",
            "1560/1564 [============================>.] - ETA: 0s - loss: 0.2702 - accuracy: 0.8600\n",
            "Epoch 2: val_accuracy did not improve from 0.85882\n",
            "1564/1564 [==============================] - 6s 4ms/step - loss: 0.2703 - accuracy: 0.8600 - val_loss: 0.2711 - val_accuracy: 0.8588\n",
            "Epoch 3/100\n",
            "1548/1564 [============================>.] - ETA: 0s - loss: 0.2708 - accuracy: 0.8595\n",
            "Epoch 3: val_accuracy did not improve from 0.85882\n",
            "1564/1564 [==============================] - 6s 4ms/step - loss: 0.2703 - accuracy: 0.8600 - val_loss: 0.2716 - val_accuracy: 0.8588\n",
            "Epoch 4/100\n",
            "1554/1564 [============================>.] - ETA: 0s - loss: 0.2701 - accuracy: 0.8602\n",
            "Epoch 4: val_accuracy did not improve from 0.85882\n",
            "1564/1564 [==============================] - 6s 4ms/step - loss: 0.2702 - accuracy: 0.8600 - val_loss: 0.2710 - val_accuracy: 0.8588\n",
            "Epoch 5/100\n",
            "1564/1564 [==============================] - ETA: 0s - loss: 0.2701 - accuracy: 0.8600\n",
            "Epoch 5: val_accuracy did not improve from 0.85882\n",
            "1564/1564 [==============================] - 5s 3ms/step - loss: 0.2701 - accuracy: 0.8600 - val_loss: 0.2710 - val_accuracy: 0.8588\n",
            "Epoch 5: early stopping\n",
            "iteration: 6\n",
            "{'layers': 3, 'lr': 0.1, 'N hidden': 20, 'Mini-batch size': 8, 'lrd': 0.0001, 'dropout': 0.4}\n",
            "Epoch 1/100\n",
            "3113/3128 [============================>.] - ETA: 0s - loss: 0.4165 - accuracy: 0.8600\n",
            "Epoch 1: val_accuracy did not improve from 0.85882\n",
            "3128/3128 [==============================] - 12s 4ms/step - loss: 0.4171 - accuracy: 0.8597 - val_loss: 0.4207 - val_accuracy: 0.8588\n",
            "Epoch 2/100\n",
            "3108/3128 [============================>.] - ETA: 0s - loss: 0.4085 - accuracy: 0.8602\n",
            "Epoch 2: val_accuracy did not improve from 0.85882\n",
            "3128/3128 [==============================] - 12s 4ms/step - loss: 0.4089 - accuracy: 0.8600 - val_loss: 0.4217 - val_accuracy: 0.8588\n",
            "Epoch 3/100\n",
            "3122/3128 [============================>.] - ETA: 0s - loss: 0.4086 - accuracy: 0.8599\n",
            "Epoch 3: val_accuracy did not improve from 0.85882\n",
            "3128/3128 [==============================] - 12s 4ms/step - loss: 0.4085 - accuracy: 0.8600 - val_loss: 0.4115 - val_accuracy: 0.8588\n",
            "Epoch 4/100\n",
            "3127/3128 [============================>.] - ETA: 0s - loss: 0.4081 - accuracy: 0.8600\n",
            "Epoch 4: val_accuracy did not improve from 0.85882\n",
            "3128/3128 [==============================] - 12s 4ms/step - loss: 0.4081 - accuracy: 0.8600 - val_loss: 0.4139 - val_accuracy: 0.8588\n",
            "Epoch 5/100\n",
            "3106/3128 [============================>.] - ETA: 0s - loss: 0.4076 - accuracy: 0.8600\n",
            "Epoch 5: val_accuracy did not improve from 0.85882\n",
            "3128/3128 [==============================] - 15s 5ms/step - loss: 0.4076 - accuracy: 0.8600 - val_loss: 0.4071 - val_accuracy: 0.8588\n",
            "Epoch 5: early stopping\n",
            "iteration: 7\n",
            "{'layers': 3, 'lr': 0.0001, 'N hidden': 4, 'Mini-batch size': 8, 'lrd': 0.01, 'dropout': 0.4}\n",
            "Epoch 1/100\n",
            "3121/3128 [============================>.] - ETA: 0s - loss: 0.6733 - accuracy: 0.8557\n",
            "Epoch 1: val_accuracy did not improve from 0.85882\n",
            "3128/3128 [==============================] - 13s 4ms/step - loss: 0.6733 - accuracy: 0.8557 - val_loss: 0.6657 - val_accuracy: 0.8588\n",
            "Epoch 2/100\n",
            "3115/3128 [============================>.] - ETA: 0s - loss: 0.6624 - accuracy: 0.8601\n",
            "Epoch 2: val_accuracy did not improve from 0.85882\n",
            "3128/3128 [==============================] - 12s 4ms/step - loss: 0.6624 - accuracy: 0.8600 - val_loss: 0.6598 - val_accuracy: 0.8588\n",
            "Epoch 3/100\n",
            "3113/3128 [============================>.] - ETA: 0s - loss: 0.6579 - accuracy: 0.8599\n",
            "Epoch 3: val_accuracy did not improve from 0.85882\n",
            "3128/3128 [==============================] - 14s 4ms/step - loss: 0.6578 - accuracy: 0.8600 - val_loss: 0.6562 - val_accuracy: 0.8588\n",
            "Epoch 4/100\n",
            "3125/3128 [============================>.] - ETA: 0s - loss: 0.6548 - accuracy: 0.8599\n",
            "Epoch 4: val_accuracy did not improve from 0.85882\n",
            "3128/3128 [==============================] - 12s 4ms/step - loss: 0.6548 - accuracy: 0.8600 - val_loss: 0.6536 - val_accuracy: 0.8588\n",
            "Epoch 5/100\n",
            "3127/3128 [============================>.] - ETA: 0s - loss: 0.6525 - accuracy: 0.8600\n",
            "Epoch 5: val_accuracy did not improve from 0.85882\n",
            "3128/3128 [==============================] - 12s 4ms/step - loss: 0.6525 - accuracy: 0.8600 - val_loss: 0.6515 - val_accuracy: 0.8588\n",
            "Epoch 5: early stopping\n",
            "iteration: 8\n",
            "{'layers': 1, 'lr': 0.0001, 'N hidden': 20, 'Mini-batch size': 16, 'lrd': 0.1, 'dropout': 0}\n",
            "Epoch 1/100\n",
            "1545/1564 [============================>.] - ETA: 0s - loss: 0.6878 - accuracy: 0.4217\n",
            "Epoch 1: val_accuracy did not improve from 0.85882\n",
            "1564/1564 [==============================] - 6s 4ms/step - loss: 0.6876 - accuracy: 0.4218 - val_loss: 0.6699 - val_accuracy: 0.4297\n",
            "Epoch 2/100\n",
            "1543/1564 [============================>.] - ETA: 0s - loss: 0.6640 - accuracy: 0.5400\n",
            "Epoch 2: val_accuracy did not improve from 0.85882\n",
            "1564/1564 [==============================] - 5s 3ms/step - loss: 0.6640 - accuracy: 0.5403 - val_loss: 0.6582 - val_accuracy: 0.5717\n",
            "Epoch 3/100\n",
            "1557/1564 [============================>.] - ETA: 0s - loss: 0.6552 - accuracy: 0.5692\n",
            "Epoch 3: val_accuracy did not improve from 0.85882\n",
            "1564/1564 [==============================] - 6s 4ms/step - loss: 0.6552 - accuracy: 0.5691 - val_loss: 0.6516 - val_accuracy: 0.5717\n",
            "Epoch 4/100\n",
            "1555/1564 [============================>.] - ETA: 0s - loss: 0.6497 - accuracy: 0.5744\n",
            "Epoch 4: val_accuracy did not improve from 0.85882\n",
            "1564/1564 [==============================] - 9s 6ms/step - loss: 0.6496 - accuracy: 0.5755 - val_loss: 0.6469 - val_accuracy: 0.7144\n",
            "Epoch 5/100\n",
            "1561/1564 [============================>.] - ETA: 0s - loss: 0.6455 - accuracy: 0.8172\n",
            "Epoch 5: val_accuracy did not improve from 0.85882\n",
            "1564/1564 [==============================] - 6s 4ms/step - loss: 0.6455 - accuracy: 0.8174 - val_loss: 0.6432 - val_accuracy: 0.8588\n",
            "Epoch 5: early stopping\n",
            "iteration: 9\n",
            "{'layers': 3, 'lr': 0.001, 'N hidden': 25, 'Mini-batch size': 16, 'lrd': 0.0001, 'dropout': 0.3}\n",
            "Epoch 1/100\n",
            "1557/1564 [============================>.] - ETA: 0s - loss: 0.2884 - accuracy: 0.8586\n",
            "Epoch 1: val_accuracy did not improve from 0.85882\n",
            "1564/1564 [==============================] - 7s 4ms/step - loss: 0.2882 - accuracy: 0.8586 - val_loss: 0.2709 - val_accuracy: 0.8588\n",
            "Epoch 2/100\n",
            "1558/1564 [============================>.] - ETA: 0s - loss: 0.2707 - accuracy: 0.8601\n",
            "Epoch 2: val_accuracy did not improve from 0.85882\n",
            "1564/1564 [==============================] - 6s 4ms/step - loss: 0.2709 - accuracy: 0.8600 - val_loss: 0.2711 - val_accuracy: 0.8588\n",
            "Epoch 3/100\n",
            "1543/1564 [============================>.] - ETA: 0s - loss: 0.2702 - accuracy: 0.8601\n",
            "Epoch 3: val_accuracy did not improve from 0.85882\n",
            "1564/1564 [==============================] - 7s 4ms/step - loss: 0.2706 - accuracy: 0.8600 - val_loss: 0.2726 - val_accuracy: 0.8588\n",
            "Epoch 4/100\n",
            "1550/1564 [============================>.] - ETA: 0s - loss: 0.2703 - accuracy: 0.8604\n",
            "Epoch 4: val_accuracy did not improve from 0.85882\n",
            "1564/1564 [==============================] - 6s 4ms/step - loss: 0.2706 - accuracy: 0.8600 - val_loss: 0.2709 - val_accuracy: 0.8588\n",
            "Epoch 5/100\n",
            "1554/1564 [============================>.] - ETA: 0s - loss: 0.2703 - accuracy: 0.8600\n",
            "Epoch 5: val_accuracy did not improve from 0.85882\n",
            "1564/1564 [==============================] - 7s 4ms/step - loss: 0.2702 - accuracy: 0.8600 - val_loss: 0.2710 - val_accuracy: 0.8588\n",
            "Epoch 5: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_ifthenelse = [key for key, value in ifthenelse_models.items() if value == max(ifthenelse_models.values())]\n",
        "print(best_model_ifthenelse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-K2Bl2jg0MG",
        "outputId": "79a2479a-91ee-4730-f150-d7859305642c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"{'layers': 4, 'lr': 0.001, 'N hidden': 25, 'Mini-batch size': 16, 'lrd': 0.0001, 'dropout': 0.3}\", \"{'layers': 1, 'lr': 0.01, 'N hidden': 5, 'Mini-batch size': 8, 'lrd': 0.001, 'dropout': 0.4}\", \"{'layers': 4, 'lr': 0.1, 'N hidden': 25, 'Mini-batch size': 64, 'lrd': 0.001, 'dropout': 0.4}\", \"{'layers': 3, 'lr': 0.1, 'N hidden': 10, 'Mini-batch size': 32, 'lrd': 0.1, 'dropout': 0}\", \"{'layers': 1, 'lr': 0.001, 'N hidden': 25, 'Mini-batch size': 64, 'lrd': 0.01, 'dropout': 0.4}\", \"{'layers': 2, 'lr': 0.01, 'N hidden': 25, 'Mini-batch size': 16, 'lrd': 0.0001, 'dropout': 0}\", \"{'layers': 3, 'lr': 0.1, 'N hidden': 20, 'Mini-batch size': 8, 'lrd': 0.0001, 'dropout': 0.4}\", \"{'layers': 3, 'lr': 0.0001, 'N hidden': 4, 'Mini-batch size': 8, 'lrd': 0.01, 'dropout': 0.4}\", \"{'layers': 1, 'lr': 0.0001, 'N hidden': 20, 'Mini-batch size': 16, 'lrd': 0.1, 'dropout': 0}\", \"{'layers': 3, 'lr': 0.001, 'N hidden': 25, 'Mini-batch size': 16, 'lrd': 0.0001, 'dropout': 0.3}\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_params_consecutive = {'layers': 4, 'lr': 0.001, 'N hidden': 25, 'Mini-batch size': 16, 'lrd': 0.0001, 'dropout': 0.3}"
      ],
      "metadata": {
        "id": "ciBYs2e4hRp5"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reconstructed_best_model_ifthenelse = keras.models.load_model(\"/content/drive/My Drive/ML_trace_predictor/ifthenelse.h5\")"
      ],
      "metadata": {
        "id": "x4nKZ2eFihpK"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = reconstructed_best_model_ifthenelse.evaluate(ifthenelse_onehot_test_dataset, ifthenelse_onehot_test_labels, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOo07cQWitUf",
        "outputId": "129680ab-c633-458c-b687-74638da101f8"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.27308595180511475\n",
            "Test accuracy: 0.8568932414054871\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nested_models = random_search(params,10,nested_onehot_training_dataset,nested_onehot_training_labels,nested_onehot_val_dataset,nested_onehot_val_labels,nested_onehot_training_dataset.shape[1],nested_onehot_training_labels.shape[1],\"nested\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuAMD4hRjIqv",
        "outputId": "86e6653c-f9c6-44d7-a07f-9d79fcfa4ae5"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration: 0\n",
            "{'layers': 3, 'lr': 0.0001, 'N hidden': 10, 'Mini-batch size': 8, 'lrd': 0.001, 'dropout': 0}\n",
            "Epoch 1/100\n",
            "3123/3128 [============================>.] - ETA: 0s - loss: 1.8957 - accuracy: 0.4112\n",
            "Epoch 1: val_accuracy improved from -inf to 0.59768, saving model to /content/drive/My Drive/ML_trace_predictor/nested.h5\n",
            "3128/3128 [==============================] - 14s 4ms/step - loss: 1.8954 - accuracy: 0.4115 - val_loss: 1.6055 - val_accuracy: 0.5977\n",
            "Epoch 2/100\n",
            "3127/3128 [============================>.] - ETA: 0s - loss: 1.4933 - accuracy: 0.6179\n",
            "Epoch 2: val_accuracy improved from 0.59768 to 0.62054, saving model to /content/drive/My Drive/ML_trace_predictor/nested.h5\n",
            "3128/3128 [==============================] - 13s 4ms/step - loss: 1.4932 - accuracy: 0.6179 - val_loss: 1.4057 - val_accuracy: 0.6205\n",
            "Epoch 3/100\n",
            "3120/3128 [============================>.] - ETA: 0s - loss: 1.3583 - accuracy: 0.6203\n",
            "Epoch 3: val_accuracy did not improve from 0.62054\n",
            "3128/3128 [==============================] - 12s 4ms/step - loss: 1.3582 - accuracy: 0.6203 - val_loss: 1.3200 - val_accuracy: 0.6205\n",
            "Epoch 4/100\n",
            "3118/3128 [============================>.] - ETA: 0s - loss: 1.2960 - accuracy: 0.6201\n",
            "Epoch 4: val_accuracy did not improve from 0.62054\n",
            "3128/3128 [==============================] - 12s 4ms/step - loss: 1.2955 - accuracy: 0.6203 - val_loss: 1.2729 - val_accuracy: 0.6205\n",
            "Epoch 5/100\n",
            "3113/3128 [============================>.] - ETA: 0s - loss: 1.2571 - accuracy: 0.6204\n",
            "Epoch 5: val_accuracy did not improve from 0.62054\n",
            "3128/3128 [==============================] - 13s 4ms/step - loss: 1.2570 - accuracy: 0.6203 - val_loss: 1.2405 - val_accuracy: 0.6205\n",
            "Epoch 5: early stopping\n",
            "iteration: 1\n",
            "{'layers': 1, 'lr': 0.01, 'N hidden': 5, 'Mini-batch size': 32, 'lrd': 0.1, 'dropout': 0}\n",
            "Epoch 1/100\n",
            "776/782 [============================>.] - ETA: 0s - loss: 1.2803 - accuracy: 0.6140\n",
            "Epoch 1: val_accuracy did not improve from 0.62054\n",
            "782/782 [==============================] - 4s 4ms/step - loss: 1.2798 - accuracy: 0.6139 - val_loss: 1.1526 - val_accuracy: 0.6205\n",
            "Epoch 2/100\n",
            "772/782 [============================>.] - ETA: 0s - loss: 1.1159 - accuracy: 0.6206\n",
            "Epoch 2: val_accuracy did not improve from 0.62054\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 1.1165 - accuracy: 0.6203 - val_loss: 1.0848 - val_accuracy: 0.6205\n",
            "Epoch 3/100\n",
            "757/782 [============================>.] - ETA: 0s - loss: 1.0661 - accuracy: 0.6319\n",
            "Epoch 3: val_accuracy improved from 0.62054 to 0.65423, saving model to /content/drive/My Drive/ML_trace_predictor/nested.h5\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 1.0664 - accuracy: 0.6322 - val_loss: 1.0472 - val_accuracy: 0.6542\n",
            "Epoch 4/100\n",
            "769/782 [============================>.] - ETA: 0s - loss: 1.0344 - accuracy: 0.6727\n",
            "Epoch 4: val_accuracy improved from 0.65423 to 0.68951, saving model to /content/drive/My Drive/ML_trace_predictor/nested.h5\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.0355 - accuracy: 0.6725 - val_loss: 1.0218 - val_accuracy: 0.6895\n",
            "Epoch 5/100\n",
            "762/782 [============================>.] - ETA: 0s - loss: 1.0131 - accuracy: 0.6956\n",
            "Epoch 5: val_accuracy improved from 0.68951 to 0.69890, saving model to /content/drive/My Drive/ML_trace_predictor/nested.h5\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.0136 - accuracy: 0.6955 - val_loss: 1.0028 - val_accuracy: 0.6989\n",
            "Epoch 5: early stopping\n",
            "iteration: 2\n",
            "{'layers': 1, 'lr': 0.01, 'N hidden': 25, 'Mini-batch size': 64, 'lrd': 0.0001, 'dropout': 0.3}\n",
            "Epoch 1/100\n",
            "369/391 [===========================>..] - ETA: 0s - loss: 0.7414 - accuracy: 0.7421\n",
            "Epoch 1: val_accuracy improved from 0.69890 to 0.77966, saving model to /content/drive/My Drive/ML_trace_predictor/nested.h5\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.7307 - accuracy: 0.7440 - val_loss: 0.5277 - val_accuracy: 0.7797\n",
            "Epoch 2/100\n",
            "371/391 [===========================>..] - ETA: 0s - loss: 0.5512 - accuracy: 0.7684\n",
            "Epoch 2: val_accuracy did not improve from 0.77966\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.5507 - accuracy: 0.7683 - val_loss: 0.5073 - val_accuracy: 0.7784\n",
            "Epoch 3/100\n",
            "379/391 [============================>.] - ETA: 0s - loss: 0.5377 - accuracy: 0.7691\n",
            "Epoch 3: val_accuracy did not improve from 0.77966\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.5382 - accuracy: 0.7688 - val_loss: 0.5014 - val_accuracy: 0.7797\n",
            "Epoch 4/100\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.5301 - accuracy: 0.7707\n",
            "Epoch 4: val_accuracy did not improve from 0.77966\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5304 - accuracy: 0.7702 - val_loss: 0.5010 - val_accuracy: 0.7778\n",
            "Epoch 5/100\n",
            "381/391 [============================>.] - ETA: 0s - loss: 0.5273 - accuracy: 0.7694\n",
            "Epoch 5: val_accuracy did not improve from 0.77966\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 0.5277 - accuracy: 0.7692 - val_loss: 0.5041 - val_accuracy: 0.7791\n",
            "Epoch 5: early stopping\n",
            "iteration: 3\n",
            "{'layers': 1, 'lr': 0.001, 'N hidden': 25, 'Mini-batch size': 16, 'lrd': 0.01, 'dropout': 0}\n",
            "Epoch 1/100\n",
            "1550/1564 [============================>.] - ETA: 0s - loss: 1.2443 - accuracy: 0.6225\n",
            "Epoch 1: val_accuracy did not improve from 0.77966\n",
            "1564/1564 [==============================] - 7s 4ms/step - loss: 1.2431 - accuracy: 0.6224 - val_loss: 1.0407 - val_accuracy: 0.6527\n",
            "Epoch 2/100\n",
            "1563/1564 [============================>.] - ETA: 0s - loss: 0.9863 - accuracy: 0.6836\n",
            "Epoch 2: val_accuracy did not improve from 0.77966\n",
            "1564/1564 [==============================] - 6s 4ms/step - loss: 0.9863 - accuracy: 0.6836 - val_loss: 0.9451 - val_accuracy: 0.7096\n",
            "Epoch 3/100\n",
            "1552/1564 [============================>.] - ETA: 0s - loss: 0.9158 - accuracy: 0.7105\n",
            "Epoch 3: val_accuracy did not improve from 0.77966\n",
            "1564/1564 [==============================] - 5s 3ms/step - loss: 0.9151 - accuracy: 0.7108 - val_loss: 0.8929 - val_accuracy: 0.7131\n",
            "Epoch 4/100\n",
            "1554/1564 [============================>.] - ETA: 0s - loss: 0.8737 - accuracy: 0.7224\n",
            "Epoch 4: val_accuracy did not improve from 0.77966\n",
            "1564/1564 [==============================] - 6s 4ms/step - loss: 0.8726 - accuracy: 0.7228 - val_loss: 0.8582 - val_accuracy: 0.7287\n",
            "Epoch 5/100\n",
            "1561/1564 [============================>.] - ETA: 0s - loss: 0.8429 - accuracy: 0.7317\n",
            "Epoch 5: val_accuracy did not improve from 0.77966\n",
            "1564/1564 [==============================] - 6s 4ms/step - loss: 0.8433 - accuracy: 0.7315 - val_loss: 0.8332 - val_accuracy: 0.7446\n",
            "Epoch 5: early stopping\n",
            "iteration: 4\n",
            "{'layers': 2, 'lr': 0.001, 'N hidden': 4, 'Mini-batch size': 16, 'lrd': 0.0001, 'dropout': 0.3}\n",
            "Epoch 1/100\n",
            "1547/1564 [============================>.] - ETA: 0s - loss: 1.6215 - accuracy: 0.4900\n",
            "Epoch 1: val_accuracy did not improve from 0.77966\n",
            "1564/1564 [==============================] - 7s 4ms/step - loss: 1.6181 - accuracy: 0.4907 - val_loss: 0.9937 - val_accuracy: 0.6706\n",
            "Epoch 2/100\n",
            "1558/1564 [============================>.] - ETA: 0s - loss: 1.2158 - accuracy: 0.5759\n",
            "Epoch 2: val_accuracy did not improve from 0.77966\n",
            "1564/1564 [==============================] - 6s 4ms/step - loss: 1.2157 - accuracy: 0.5760 - val_loss: 0.8866 - val_accuracy: 0.7277\n",
            "Epoch 3/100\n",
            "1554/1564 [============================>.] - ETA: 0s - loss: 1.1349 - accuracy: 0.6154\n",
            "Epoch 3: val_accuracy did not improve from 0.77966\n",
            "1564/1564 [==============================] - 6s 4ms/step - loss: 1.1349 - accuracy: 0.6152 - val_loss: 0.8479 - val_accuracy: 0.7277\n",
            "Epoch 4/100\n",
            "1555/1564 [============================>.] - ETA: 0s - loss: 1.1049 - accuracy: 0.6175\n",
            "Epoch 4: val_accuracy did not improve from 0.77966\n",
            "1564/1564 [==============================] - 6s 4ms/step - loss: 1.1052 - accuracy: 0.6172 - val_loss: 0.8261 - val_accuracy: 0.7277\n",
            "Epoch 5/100\n",
            "1554/1564 [============================>.] - ETA: 0s - loss: 1.0824 - accuracy: 0.6231\n",
            "Epoch 5: val_accuracy did not improve from 0.77966\n",
            "1564/1564 [==============================] - 5s 3ms/step - loss: 1.0824 - accuracy: 0.6231 - val_loss: 0.8096 - val_accuracy: 0.7277\n",
            "Epoch 5: early stopping\n",
            "iteration: 5\n",
            "{'layers': 3, 'lr': 0.01, 'N hidden': 10, 'Mini-batch size': 8, 'lrd': 0.01, 'dropout': 0}\n",
            "Epoch 1/100\n",
            "3122/3128 [============================>.] - ETA: 0s - loss: 0.7155 - accuracy: 0.7433\n",
            "Epoch 1: val_accuracy improved from 0.77966 to 0.77990, saving model to /content/drive/My Drive/ML_trace_predictor/nested.h5\n",
            "3128/3128 [==============================] - 12s 4ms/step - loss: 0.7150 - accuracy: 0.7434 - val_loss: 0.5438 - val_accuracy: 0.7799\n",
            "Epoch 2/100\n",
            "3114/3128 [============================>.] - ETA: 0s - loss: 0.5347 - accuracy: 0.7765\n",
            "Epoch 2: val_accuracy did not improve from 0.77990\n",
            "3128/3128 [==============================] - 11s 4ms/step - loss: 0.5346 - accuracy: 0.7765 - val_loss: 0.5258 - val_accuracy: 0.7797\n",
            "Epoch 3/100\n",
            "3108/3128 [============================>.] - ETA: 0s - loss: 0.5237 - accuracy: 0.7769\n",
            "Epoch 3: val_accuracy did not improve from 0.77990\n",
            "3128/3128 [==============================] - 13s 4ms/step - loss: 0.5239 - accuracy: 0.7768 - val_loss: 0.5202 - val_accuracy: 0.7797\n",
            "Epoch 4/100\n",
            "3113/3128 [============================>.] - ETA: 0s - loss: 0.5188 - accuracy: 0.7767\n",
            "Epoch 4: val_accuracy did not improve from 0.77990\n",
            "3128/3128 [==============================] - 12s 4ms/step - loss: 0.5188 - accuracy: 0.7767 - val_loss: 0.5164 - val_accuracy: 0.7797\n",
            "Epoch 5/100\n",
            "3127/3128 [============================>.] - ETA: 0s - loss: 0.5161 - accuracy: 0.7767\n",
            "Epoch 5: val_accuracy did not improve from 0.77990\n",
            "3128/3128 [==============================] - 11s 4ms/step - loss: 0.5161 - accuracy: 0.7767 - val_loss: 0.5140 - val_accuracy: 0.7797\n",
            "Epoch 5: early stopping\n",
            "iteration: 6\n",
            "{'layers': 1, 'lr': 0.01, 'N hidden': 8, 'Mini-batch size': 16, 'lrd': 0.001, 'dropout': 0.3}\n",
            "Epoch 1/100\n",
            "1562/1564 [============================>.] - ETA: 0s - loss: 0.9019 - accuracy: 0.6970\n",
            "Epoch 1: val_accuracy did not improve from 0.77990\n",
            "1564/1564 [==============================] - 8s 5ms/step - loss: 0.9018 - accuracy: 0.6970 - val_loss: 0.5990 - val_accuracy: 0.7797\n",
            "Epoch 2/100\n",
            "1558/1564 [============================>.] - ETA: 0s - loss: 0.7617 - accuracy: 0.7269\n",
            "Epoch 2: val_accuracy did not improve from 0.77990\n",
            "1564/1564 [==============================] - 6s 4ms/step - loss: 0.7607 - accuracy: 0.7274 - val_loss: 0.5698 - val_accuracy: 0.7797\n",
            "Epoch 3/100\n",
            "1556/1564 [============================>.] - ETA: 0s - loss: 0.7495 - accuracy: 0.7275\n",
            "Epoch 3: val_accuracy did not improve from 0.77990\n",
            "1564/1564 [==============================] - 5s 3ms/step - loss: 0.7491 - accuracy: 0.7277 - val_loss: 0.5677 - val_accuracy: 0.7797\n",
            "Epoch 4/100\n",
            "1549/1564 [============================>.] - ETA: 0s - loss: 0.7410 - accuracy: 0.7270\n",
            "Epoch 4: val_accuracy did not improve from 0.77990\n",
            "1564/1564 [==============================] - 5s 3ms/step - loss: 0.7408 - accuracy: 0.7270 - val_loss: 0.5600 - val_accuracy: 0.7797\n",
            "Epoch 5/100\n",
            "1556/1564 [============================>.] - ETA: 0s - loss: 0.7291 - accuracy: 0.7286\n",
            "Epoch 5: val_accuracy did not improve from 0.77990\n",
            "1564/1564 [==============================] - 5s 3ms/step - loss: 0.7292 - accuracy: 0.7287 - val_loss: 0.5538 - val_accuracy: 0.7797\n",
            "Epoch 5: early stopping\n",
            "iteration: 7\n",
            "{'layers': 1, 'lr': 0.0001, 'N hidden': 10, 'Mini-batch size': 16, 'lrd': 0.01, 'dropout': 0}\n",
            "Epoch 1/100\n",
            "1544/1564 [============================>.] - ETA: 0s - loss: 2.3101 - accuracy: 0.4177\n",
            "Epoch 1: val_accuracy did not improve from 0.77990\n",
            "1564/1564 [==============================] - 7s 4ms/step - loss: 2.3089 - accuracy: 0.4193 - val_loss: 2.2473 - val_accuracy: 0.4999\n",
            "Epoch 2/100\n",
            "1560/1564 [============================>.] - ETA: 0s - loss: 2.2171 - accuracy: 0.5288\n",
            "Epoch 2: val_accuracy did not improve from 0.77990\n",
            "1564/1564 [==============================] - 6s 4ms/step - loss: 2.2171 - accuracy: 0.5289 - val_loss: 2.1942 - val_accuracy: 0.5408\n",
            "Epoch 3/100\n",
            "1545/1564 [============================>.] - ETA: 0s - loss: 2.1761 - accuracy: 0.5468\n",
            "Epoch 3: val_accuracy did not improve from 0.77990\n",
            "1564/1564 [==============================] - 5s 3ms/step - loss: 2.1758 - accuracy: 0.5469 - val_loss: 2.1614 - val_accuracy: 0.5552\n",
            "Epoch 4/100\n",
            "1542/1564 [============================>.] - ETA: 0s - loss: 2.1478 - accuracy: 0.5580\n",
            "Epoch 4: val_accuracy did not improve from 0.77990\n",
            "1564/1564 [==============================] - 6s 4ms/step - loss: 2.1482 - accuracy: 0.5574 - val_loss: 2.1379 - val_accuracy: 0.5541\n",
            "Epoch 5/100\n",
            "1551/1564 [============================>.] - ETA: 0s - loss: 2.1276 - accuracy: 0.5573\n",
            "Epoch 5: val_accuracy did not improve from 0.77990\n",
            "1564/1564 [==============================] - 6s 4ms/step - loss: 2.1275 - accuracy: 0.5572 - val_loss: 2.1196 - val_accuracy: 0.5552\n",
            "Epoch 5: early stopping\n",
            "iteration: 8\n",
            "{'layers': 2, 'lr': 0.0001, 'N hidden': 4, 'Mini-batch size': 32, 'lrd': 0.01, 'dropout': 0.4}\n",
            "Epoch 1/100\n",
            "762/782 [============================>.] - ETA: 0s - loss: 2.4516 - accuracy: 0.2622\n",
            "Epoch 1: val_accuracy did not improve from 0.77990\n",
            "782/782 [==============================] - 67s 4ms/step - loss: 2.4507 - accuracy: 0.2623 - val_loss: 2.4230 - val_accuracy: 0.3680\n",
            "Epoch 2/100\n",
            "781/782 [============================>.] - ETA: 0s - loss: 2.4135 - accuracy: 0.2792\n",
            "Epoch 2: val_accuracy did not improve from 0.77990\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 2.4135 - accuracy: 0.2793 - val_loss: 2.3971 - val_accuracy: 0.3697\n",
            "Epoch 3/100\n",
            "773/782 [============================>.] - ETA: 0s - loss: 2.3930 - accuracy: 0.2861\n",
            "Epoch 3: val_accuracy did not improve from 0.77990\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 2.3931 - accuracy: 0.2859 - val_loss: 2.3797 - val_accuracy: 0.3707\n",
            "Epoch 4/100\n",
            "773/782 [============================>.] - ETA: 0s - loss: 2.3808 - accuracy: 0.2815\n",
            "Epoch 4: val_accuracy did not improve from 0.77990\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 2.3807 - accuracy: 0.2816 - val_loss: 2.3666 - val_accuracy: 0.3669\n",
            "Epoch 5/100\n",
            "772/782 [============================>.] - ETA: 0s - loss: 2.3708 - accuracy: 0.2878\n",
            "Epoch 5: val_accuracy did not improve from 0.77990\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 2.3705 - accuracy: 0.2881 - val_loss: 2.3561 - val_accuracy: 0.3634\n",
            "Epoch 5: early stopping\n",
            "iteration: 9\n",
            "{'layers': 4, 'lr': 0.001, 'N hidden': 5, 'Mini-batch size': 32, 'lrd': 0.1, 'dropout': 0}\n",
            "Epoch 1/100\n",
            "773/782 [============================>.] - ETA: 0s - loss: 2.4015 - accuracy: 0.2076\n",
            "Epoch 1: val_accuracy did not improve from 0.77990\n",
            "782/782 [==============================] - 4s 4ms/step - loss: 2.4011 - accuracy: 0.2074 - val_loss: 2.3673 - val_accuracy: 0.2077\n",
            "Epoch 2/100\n",
            "774/782 [============================>.] - ETA: 0s - loss: 2.3496 - accuracy: 0.2107\n",
            "Epoch 2: val_accuracy did not improve from 0.77990\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 2.3495 - accuracy: 0.2108 - val_loss: 2.3352 - val_accuracy: 0.2077\n",
            "Epoch 3/100\n",
            "781/782 [============================>.] - ETA: 0s - loss: 2.3229 - accuracy: 0.2109\n",
            "Epoch 3: val_accuracy did not improve from 0.77990\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 2.3229 - accuracy: 0.2108 - val_loss: 2.3131 - val_accuracy: 0.2077\n",
            "Epoch 4/100\n",
            "775/782 [============================>.] - ETA: 0s - loss: 2.3034 - accuracy: 0.2108\n",
            "Epoch 4: val_accuracy did not improve from 0.77990\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 2.3034 - accuracy: 0.2108 - val_loss: 2.2959 - val_accuracy: 0.2077\n",
            "Epoch 5/100\n",
            "778/782 [============================>.] - ETA: 0s - loss: 2.2881 - accuracy: 0.2109\n",
            "Epoch 5: val_accuracy did not improve from 0.77990\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 2.2881 - accuracy: 0.2108 - val_loss: 2.2824 - val_accuracy: 0.2077\n",
            "Epoch 5: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_nested = [key for key, value in nested_models.items() if value == max(nested_models.values())]\n",
        "print(best_model_nested)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywTs2g7XjGCF",
        "outputId": "2a4d5d95-54d2-47cb-e37f-aac343758368"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"{'layers': 3, 'lr': 0.01, 'N hidden': 10, 'Mini-batch size': 8, 'lrd': 0.01, 'dropout': 0}\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reconstructed_best_model_nested = keras.models.load_model(\"/content/drive/My Drive/ML_trace_predictor/nested.h5\")"
      ],
      "metadata": {
        "id": "dd62PzWFlTYe"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = reconstructed_best_model_nested.evaluate(nested_onehot_test_dataset, nested_onehot_test_labels, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfDclYd6lYt_",
        "outputId": "23f41c34-9abc-4fe4-b531-123b9da15651"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.5434647798538208\n",
            "Test accuracy: 0.7793281078338623\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "index = np.arange(3)\n",
        "bar_width = 0.35\n",
        "opacity = 0.8\n",
        "rects2 = plt.bar(index + bar_width, [1-0.9990,1-0.8568932414054871,1-0.7793281078338623], bar_width,\n",
        "                    alpha=opacity,\n",
        "                    color='g',\n",
        "                    label='Test Error')\n",
        "\n",
        "plt.ylabel('Error')\n",
        "plt.title('NN Test Errors')\n",
        "plt.xticks(index + bar_width, ('Consecutive', 'If-then-else', 'Nested'))\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "oR0YSE4mldol",
        "outputId": "3a11cf1e-a352-4405-c06e-0d00864f2fea"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}